{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def dataProduce(filename,root_path,p,init_weidu):\n",
    "    with open(filename,\"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['SUB_ID']+list(range(1,init_weidu)))\n",
    "        file_list = os.listdir(root_path)\n",
    "        for filename in file_list:\n",
    "            file_path = root_path + \"\\\\\" + filename\n",
    "            data = np.loadtxt(file_path).transpose()\n",
    "            data = np.corrcoef(data)\n",
    "            np.arctanh(data - np.eye(data.shape[0]))\n",
    "            m, n = np.shape(data)\n",
    "            # print(m,n)\n",
    "            data_list = []\n",
    "            for i in range(m):\n",
    "                for j in range(i + 1, n):\n",
    "                    data_list.append(data[i][j])\n",
    "            writer.writerow([filename.split(\"_\")[p][2:]]+data_list)\n",
    "\n",
    "def dataInsertLabel(filename,aal_fea):\n",
    "    aal_fea = list(map(str, aal_fea))\n",
    "    aal_fea.insert(0, 'SUB_ID')\n",
    "    raw_data = pd.read_csv(filename)\n",
    "    data = pd.DataFrame(raw_data,columns=aal_fea)\n",
    "    return data\n",
    "\n",
    "def fea(aalFeaPer,aalFeaSel,aalFeaRid,p,s,r,allnum):\n",
    "    feature_per = feaSel(aalFeaPer,allnum,p)\n",
    "    feature_sel = feaSel(aalFeaSel,allnum,s)\n",
    "    feature_rid = feaSel(aalFeaRid,allnum,r)\n",
    "    features = set(feature_per) & set(feature_sel) & set(feature_rid)\n",
    "    features = list(features)\n",
    "    return features,len(features)\n",
    "\n",
    "def feaSel(aalFeaPer,bigW,pinlv):\n",
    "    aalFeaPer.value_counts()\n",
    "    lie = list(aalFeaPer.values)\n",
    "    feature_per = []\n",
    "    for i in range(1, bigW+1):\n",
    "        if lie[i - 1] >= pinlv:\n",
    "            feature_per.append(i)\n",
    "    return feature_per"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "YALE\n",
      "==================================================\n",
      "YALE log3212\n",
      "test_acc 0.7416666666666667\n",
      "precision 0.7207613731297943\n",
      "recall 0.7944444444444445\n",
      "f1 0.7550351363509258\n",
      "auc_score 0.7416666666666668\n",
      "----------------------------------------------------------------------------------------\n",
      "UM_2\n",
      "==================================================\n",
      "UM_2 log3212\n",
      "test_acc 0.759375\n",
      "precision 0.6497592019263846\n",
      "recall 0.8846153846153847\n",
      "f1 0.748978494623656\n",
      "auc_score 0.7791497975708502\n",
      "----------------------------------------------------------------------------------------\n",
      "OLIN\n",
      "==================================================\n",
      "OLIN log3212\n",
      "test_acc 0.7107142857142857\n",
      "precision 0.7095238095238094\n",
      "recall 0.7142857142857143\n",
      "f1 0.7118226600985222\n",
      "auc_score 0.7107142857142857\n",
      "----------------------------------------------------------------------------------------\n",
      "LEUVEN_2\n",
      "==================================================\n",
      "LEUVEN_2 log3212\n",
      "test_acc 0.7357142857142858\n",
      "precision 0.9466666666666667\n",
      "recall 0.4083333333333333\n",
      "f1 0.568954248366013\n",
      "auc_score 0.6947916666666666\n",
      "----------------------------------------------------------------------------------------\n",
      "SDSU\n",
      "==================================================\n",
      "SDSU log3212\n",
      "test_acc 0.8136363636363635\n",
      "precision 0.7966666666666666\n",
      "recall 0.4666666666666666\n",
      "f1 0.5747474747474748\n",
      "auc_score 0.7052083333333334\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "aalFeaPer = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\aal\\csv\\aalMultPerPinlv.csv\", header=None)\n",
    "aalFeaSel = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\aal\\csv\\aalMultSelPinlv.csv\", header=None)\n",
    "aalFeaRid = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\aal\\csv\\aalMultRidPinlv.csv\", header=None)\n",
    "ccFeaPer = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\cc200\\csv\\cc200MultPerPinlv.csv\", header=None)\n",
    "ccFeaSel = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\cc200\\csv\\cc200MultSelPinlv.csv\", header=None)\n",
    "ccFeaRid = pd.read_csv(r\"F:\\fmri\\fmri-new\\machine\\multSite\\res\\cc200\\csv\\cc200MultRidPinlv.csv\", header=None)\n",
    "\n",
    "k_fold = 10\n",
    "#site_list = ['SDSU']\n",
    "site_list = ['YALE','UM_2','OLIN','LEUVEN_2','SDSU']\n",
    "model_path = r\"F:\\fmri\\fmri-new\\machine\\multSite\\modle\\double\"\n",
    "model_list = ['log3212']\n",
    "with open(\"result.csv\", \"w\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"site\",\"modelName\",\"test_acc\",\"test_var\",\"pre\",\n",
    "                     \"pre_var\",\"rec\",\"rec_var\",\"f1_sc\",\"f1_var\",\"auc_score\",\"auc_var\"])\n",
    "    for modelName in model_list:\n",
    "        num = modelName[-4:]\n",
    "        aals = int(num[0])\n",
    "        aalr = int(num[1])\n",
    "        ccs = int(num[2])\n",
    "        ccr = int(num[3])\n",
    "        aal_fea, weidu0 = fea(aalFeaPer, aalFeaSel, aalFeaRid, 10, aals, aalr, 6670)\n",
    "        cc200_fea, weidu1 = fea(ccFeaPer, ccFeaSel, ccFeaRid, 10, ccs, ccr, 19900)\n",
    "        weidu = weidu0+weidu1\n",
    "        for site in site_list:\n",
    "            print(\"----------------------------------------------------------------------------------------\")\n",
    "            print(site)\n",
    "            root_path = r'F:\\fmri\\fmri-new\\machine\\multSite\\jiwai_test_mult\\aal'+\"//\"+site\n",
    "            filename = site+'_test_aal.csv'\n",
    "            # 制作数据集\n",
    "            if(site == \"UM_2\" or site == \"LEUVEN_2\"):\n",
    "                dataProduce(filename,root_path,2,6671)\n",
    "            else:\n",
    "                dataProduce(filename,root_path,1,6671)\n",
    "            root_path1 = r'F:\\fmri\\fmri-new\\machine\\multSite\\jiwai_test_mult\\cc200' + \"//\" + site\n",
    "            filename1 = site + '_test_CC200.csv'\n",
    "            # 制作数据集\n",
    "            if (site == \"UM_2\" or site == \"LEUVEN_2\"):\n",
    "                dataProduce(filename1, root_path1, 2,19901)\n",
    "            else:\n",
    "                dataProduce(filename1, root_path1, 1,19901)\n",
    "            data0 = dataInsertLabel(filename,aal_fea)\n",
    "            data1 = dataInsertLabel(filename1, cc200_fea)\n",
    "            data = pd.merge(data0, data1, on='SUB_ID', how='inner')\n",
    "            phenotype_data = pd.read_csv(\"Phenotypic_V1_0b.csv\")\n",
    "            label = []\n",
    "            for i in data[\"SUB_ID\"].values:\n",
    "                if i in phenotype_data[\"SUB_ID\"].values:\n",
    "                    index = np.where(phenotype_data[\"SUB_ID\"].values == i)\n",
    "                    label.append(phenotype_data[\"DX_GROUP\"].values[index][0])\n",
    "            data.insert(loc=len(data.columns),column=\"label\",value = label)\n",
    "\n",
    "            test_data = utils.shuffle(data,random_state=0)\n",
    "            test_data = test_data.drop(\"SUB_ID\", axis=1)\n",
    "            testdata_dummies = pd.get_dummies(test_data)\n",
    "            test_features = testdata_dummies.iloc[:, :weidu]\n",
    "            X_test = test_features.values\n",
    "            y_test = testdata_dummies.iloc[:, -1].values\n",
    "            print(\"==================================================\")\n",
    "            print(site,modelName)\n",
    "            res = []\n",
    "            test_score = []\n",
    "            precision = []\n",
    "            recall = []\n",
    "            f1 =[]\n",
    "            auc = []\n",
    "            for k in range(k_fold):\n",
    "                path = model_path+\"//\"+modelName+\"//\"+str(k)+\".pkl\"\n",
    "                f = open(path,'rb')\n",
    "                model = pickle.load(f)\n",
    "                f.close()\n",
    "                y_predict = model.predict(X_test)\n",
    "                test_score.append(model.score(X_test, y_test))\n",
    "                precision.append(precision_score(y_test, y_predict, average='binary'))\n",
    "                recall.append(recall_score(y_test, y_predict, average='binary'))\n",
    "                f1.append(f1_score(y_test, y_predict, average='binary'))\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict, pos_label=2)\n",
    "                auc.append(metrics.auc(fpr, tpr))\n",
    "\n",
    "            test_acc = np.mean(test_score)\n",
    "            test_var = np.var(test_score)\n",
    "            print(\"test_acc\", test_acc)\n",
    "            pre = np.mean(precision)\n",
    "            pre_var = np.var(precision)\n",
    "            print(\"precision\", pre)\n",
    "            rec = np.mean(recall)\n",
    "            rec_var = np.var(recall)\n",
    "            print(\"recall\", rec)\n",
    "            f1_sc = np.mean(f1)\n",
    "            f1_var = np.var(f1)\n",
    "            print(\"f1\", f1_sc)\n",
    "            auc_score = np.mean(auc)\n",
    "            auc_var = np.var(auc)\n",
    "            print('auc_score', auc_score)\n",
    "            res.append(test_acc)\n",
    "            res.append(test_var)\n",
    "            res.append(pre)\n",
    "            res.append(pre_var)\n",
    "            res.append(rec)\n",
    "            res.append(rec_var)\n",
    "            res.append(f1_sc)\n",
    "            res.append(f1_var)\n",
    "            res.append(auc_score)\n",
    "            res.append(auc_var)\n",
    "            writer.writerow([site]+ [modelName]+ res)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

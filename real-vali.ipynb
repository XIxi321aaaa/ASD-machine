{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "root_path = r\"F:\\fmri\\fmri-new\\machine\\aal_NYU_10_24\"\n",
    "cc=216\n",
    "weidu = int(cc*cc/2-cc/2)\n",
    "\n",
    "data = pd.read_csv(\"new_data.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cc=216\n",
    "weidu = int(cc*cc/2-cc/2)\n",
    "\n",
    "def fea(aalFeaPer,aalFeaSel,aalFeaRid,p,s,r,allnum):\n",
    "    feature_per = feaSel(aalFeaPer,allnum,p)\n",
    "    feature_sel = feaSel(aalFeaSel,allnum,s)\n",
    "    feature_rid = feaSel(aalFeaRid,allnum,r)\n",
    "    features = set(feature_per) & set(feature_sel) & set(feature_rid)\n",
    "    return features,len(features)\n",
    "\n",
    "def feaSel(aalFeaPer,bigW,pinlv):\n",
    "    aalFeaPer.value_counts()\n",
    "    lie = list(aalFeaPer.values)\n",
    "    feature_per = []\n",
    "    for i in range(1, bigW+1):\n",
    "        if lie[i - 1] >= pinlv:\n",
    "            feature_per.append(i)\n",
    "    return feature_per\n",
    "\n",
    "def k_fold_split(dataset,k_fold,k):\n",
    "    k_sample_count = dataset.shape[0]//k_fold\n",
    "    test_begin = k_sample_count*k\n",
    "    test_end = k_sample_count*(k+1)\n",
    "    test_data = dataset[test_begin:test_end]\n",
    "    train_data = pd.concat([dataset[:test_begin],dataset[test_end:]])\n",
    "    return train_data,test_data\n",
    "\n",
    "def data_spilt(dataset):\n",
    "    dataset = dataset.drop(\"SUB_ID\",axis=1)\n",
    "    ill_data = dataset[dataset[\"label\"]==1]\n",
    "    ill_data = utils.shuffle(ill_data,random_state=0)\n",
    "    unill_data = dataset[dataset[\"label\"]==2]\n",
    "    unill_data = utils.shuffle(unill_data,random_state=0)\n",
    "    return ill_data,unill_data\n",
    "\n",
    "def k_data(ill_data,unill_data,k_fold,k,weidu):\n",
    "    train_data1, test_data1 = k_fold_split(ill_data, k_fold, k)\n",
    "    train_data2, test_data2 = k_fold_split(unill_data, k_fold, k)\n",
    "    train_data = pd.concat([train_data1, train_data2])\n",
    "    test_data = pd.concat([test_data1, test_data2])\n",
    "    train_data = utils.shuffle(train_data, random_state=0)\n",
    "    test_data = utils.shuffle(test_data, random_state=0)\n",
    "    traindata_dummies = pd.get_dummies(train_data)\n",
    "    # print(\"Features after get_dummies:\\n\",list(traindata_dummies.columns))\n",
    "    train_features = traindata_dummies.iloc[:,:weidu]\n",
    "    X_train = train_features.values\n",
    "    y_train = traindata_dummies.iloc[:,-1].values\n",
    "    testdata_dummies = pd.get_dummies(test_data)\n",
    "    test_features = testdata_dummies.iloc[:,:weidu]\n",
    "    X_test = test_features.values\n",
    "    y_test = testdata_dummies.iloc[:,-1].values\n",
    "    # print(np.shape(X_test))\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def select_fun(select,X_train,X_test,y_train):\n",
    "    select.fit(X_train,y_train)\n",
    "    X_train1 = select.transform(X_train)\n",
    "    # print(np.shape(X_train1))\n",
    "    X_test1 = select.transform(X_test)\n",
    "    return X_train1,X_test1\n",
    "\n",
    "def feadata(aal_fea):\n",
    "    aal_fea = list(map(str, aal_fea))\n",
    "    aal_fea.insert(0, 'SUB_ID')\n",
    "    aal_fea.insert(len(aal_fea),'label')\n",
    "    data = pd.DataFrame(raw_data, columns=aal_fea)\n",
    "    return data\n",
    "\n",
    "def trainTest(data,weidu):\n",
    "    test_score = []\n",
    "    train_score = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "    spec = []\n",
    "    ill_data, unill_data = data_spilt(data)\n",
    "    for k in range(k_fold):\n",
    "        X_train, X_test, y_train, y_test = k_data(ill_data, unill_data, k_fold, k,weidu)\n",
    "        # print(\"=========================================================\")\n",
    "        # print('逻辑回归')\n",
    "        model = LogisticRegression(max_iter=1000, random_state=0, class_weight={1: 0.65, 2: 0.35})\n",
    "        # print('随机森林')\n",
    "        # model = RandomForestClassifier(n_estimators=35, max_depth=7, random_state=0)\n",
    "        # print('svm')\n",
    "        # model = SVC(gamma=0.1, C=10, class_weight={1: 0.65, 2: 0.35})\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        # print(\"y_predict\",y_predict)\n",
    "        # print(\"y_test\",y_test)\n",
    "        train_score.append(model.score(X_train, y_train))\n",
    "        test_score.append(model.score(X_test, y_test))\n",
    "        precision.append(precision_score(y_test, y_predict, average='binary'))\n",
    "        recall.append(recall_score(y_test, y_predict, average='binary'))\n",
    "        f1.append(f1_score(y_test, y_predict, average='binary'))\n",
    "        tn,fp,fn,tp = confusion_matrix(y_test,y_predict).ravel()\n",
    "        spec.append(tn/(tn+fp))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict, pos_label=2)\n",
    "        auc.append(metrics.auc(fpr, tpr))\n",
    "    train_acc = np.mean(train_score)\n",
    "    test_acc = np.mean(test_score)\n",
    "    pre = np.mean(precision)\n",
    "    rec = np.mean(recall)\n",
    "    f1_sc = np.mean(f1)\n",
    "    sp = np.mean(spec)\n",
    "    auc_score = np.mean(auc)\n",
    "    return train_acc, test_acc, pre, rec, f1_sc, sp,auc_score\n",
    "\n",
    "def resHanshu(s,r,weidu):\n",
    "    # print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    aal_fea, weiduF = fea(aalFeaPer, aalFeaSel, aalFeaRid, 10, s, r,weidu)\n",
    "    print(\"s:\", s, \"r:\", r, weiduF)\n",
    "    data = feadata(aal_fea)\n",
    "    train_acc, test_acc, pre, rec, f1_sc, sp,auc_score = trainTest(data,weiduF)\n",
    "    return train_acc, test_acc, pre, rec, f1_sc, sp,auc_score,weiduF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "aalFeaPer = pd.read_csv(\"feature/PerPinlv.csv\", header=None)\n",
    "aalFeaSel = pd.read_csv(\"feature/SelPinlv.csv\", header=None)\n",
    "aalFeaRid = pd.read_csv(\"feature/ridPinlv.csv\", header=None)\n",
    "\n",
    "raw_data = pd.read_csv(\"new_data.csv\")\n",
    "\n",
    "k_fold = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: 1 r: 8 46\n",
      "0.93125\n"
     ]
    }
   ],
   "source": [
    "Train_ACC, Test_ACC, Precision, Recall,F1,SP,AUC,weiduMatrix=resHanshu(1,8,weidu)\n",
    "print(Test_ACC)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
